{"componentChunkName":"component---src-templates-blog-post-js","path":"/715125ef37493c20558b7c22e3a63779c2d38594","result":{"data":{"site":{"siteMetadata":{"title":"보노보노의 평화로운 개발 이야기"}},"current":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"715125ef37493c20558b7c22e3a63779c2d38594","text":"# 시스템 설계 및 규모 확장성 문제 3 - 웹 크롤러\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 3 - 웹 크롤러\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 웹 크롤러 : 웹에 있는 데이터를 긁어 오는 크롤러를 설계할 때, 무한루프에 빠지는 일을 방지하려면 어떻게 해야 하는가?\n\n## 무한루프는 어떻게 발생하는가?\n\n단순히 웹의 링크에 의해 만들어지는 그래프로 볼 경후, 사이클이 존재하면 무한루프가 발생할 수 있다.  \n따라서 무한루프를 막으려면 사이클을 탐지해야 한다.  \n그러기 위해선 해시테이블을 두고 이미 방문한 페이지 v의 hash[v] 값을 true로 바꿔줘야 한다.  \n이 해법은 웹을 너비 우선으로 탐색한다는 것을 의미한다.\n\n## 페이지 v를 방문한다는 것의 의미\n\n1. 단순히 URL 기준으로 판단해야 할까?\n2. 페이지 내용에 따라 방문 여부를 확인해야 할까?\n\n1번의 경우는 URL의 파라미타 값이 달라졌을 때 실제로 페이지는 달라지지 않을 때를 생각해야한다.  \n2번의 경우 같은 페이지라 할지라도 내용이 무작위로 생성된다면 다른 페이지라고 해야하는 지를 생각해봐야한다.  \n즉, 이 페이지가 저 페이지와 '다른' 페이지인지 판단하는 완벽한 방법은 없는 셈이다.\n\n이 문제를 해결하는 방법은 페이지 내용과 URL을 토대로 페이지 간의 유사성을 가늠해 보는 것이다.\n\n- 크롤러가 탐색해야 하는 항목들을 데이터베이스에 저장해 둔다.\n- 탐색 우선순위가 가장 높은 페이지를 고른다.\n- 페이지를 열어 해당 페이지의 특정한 섹션과 URL을 토대로 시그니처를 생성한다.\n- 데이터베이스 쿼리를 통해 해당 시그니처의 페이지가 최근에 탐색된 적 있는지 살핀다.\n- 만일 해당 시그니처를 갖는 페이지가 최근에 탐색된 적이 있으면 해당 페이지의 우선순위를 낮춰서 데이터베이스에 추가한다.\n- 그렇지 않다면 해당 페이지를 탐색하고, 그 페이지에 연결된 링크를 데이터베이스에 추가한다.\n"}}},"previous":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"725f6823a549cb3bd4d8fddd15021a218c438de0","text":"# [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 소셜 네트워크 : 페이스북이나 링크드인과 같은 대규모 소셜 네트워크를 위한 자료구조는 어떻게 설계하겠는가? 두 사람 사이의 최단 경로를 보여주는 알고리즘은 어떻게 설계하겠는가? (가령, 나->밥->수잔->제이슨->당신)\n\n## 내풀이\n\n'나'를 기준으로 '나'의 친구들을 연결할 필요가 있고, '친구'의 친구들을 연결할 필요가 있다.  \n각 사용자를 '노드'로 정의하고 관계를 '에지'로 정의한다고 하면 자료구조로 그래프를 사용하는 게 적절하다고 생각한다.  \n사용자 간의 경로 탐색은 너비우선탐색(BFS)로 하는 것이 적절하다고 생각한다.\n'나'를 기준으로 동심원을 그리며 찾는 것이 깊이우선탐색(DFS)보다 낫다.\nDFS는 '노드'를 기준으로 방문하지않은 노드 끝까지 갔다가 돌아가는 식으로 탐색하므로 최단경로가 아닐 수도 있다.\n\n## 책풀이\n\n## 단계1 : 문제를 단순화하기 - 수백만이 아닌 10명의 사용자로 생각해보기\n\n각 사용자를 노드, 친구 관계를 간선으로 설정하여 하나의 그래프를 만들 수 있다.  \n두 사용자 간의 경로는 한 사용자에서 시작해서 너비 우선 탐색을 돌려보면된다.\n혹은 양방향 너비 우선 탐색을 할 수도 있다.  \n하나는 출발지에서, 나머지 하나는 도착지에서 시작해서 너비 우선 탐색 두 개를 동시에 돌리는 것을 말한다.  \n두 탐색이 어느 지점에서 충돌하는 순간 경로를 찾은 것이다.\n\n**깊이우선탐색을 사용하지 않는 이유는?**  \n깊이 우선 탐색은 단순히 경로 하나를 찾기 때문이고, 이 경로가 가장 짧은 경로가 아닐 수도 있다.  \n또한, 경로 하나를 찾는 과정도 비효율적이다. 두 사용자가 1촌 관계라 하더라도 하위 트리에 존재하는 수백만 개의 노드를 탐색하게 될 수 있기 때문이다.\n\n**구현방법**  \n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-1.jpg) <br/>\n![2](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-2.jpg) <br/>\n![3](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-3.jpg) <br/>\n![4](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-4.jpg) <br/>\n\n양방향 너비 우선 탐색이 일반 너비 우선 탐색보다 빠르다.  \nS와 D가 친구 C를 공유할 때, (각 사용자는 K명의 친구가 있다, q는 경로의 길이)\n\n- 일반적인 너비 우선 탐색으로 S -> D로 가려면 대략 K + K\\*K개의 노드를 거쳐야 한다. = Q(K<sup>q</sup>)\n- 양방향 너비 우선 탐색은 S 친구 K, D친구 K로 2K 노드만 거치면 된다. = Q(K<sup>q/2</sup>)\n\n단, 양방향 너비 우선 탐색은 시작 지점과 도착 지점 모두 접근 가능할 때에나 사용 가능하다.\n\n## 단계2 : 수백만 사용자의 처리\n\n링크드인이나 페이스북 규모의 서비스를 만들 때에는 컴퓨터 하나만으로는 부족하다.  \n다시 말해 Person을 위와 같이 단순하게 설계해서는 제대로 동작하지 않을 것이라는 뜻이다.  \n우리가 찾는 '친구'는 같은 서버에 있지 않을 수도 있다.  \n따라서 ID로 구성되는 친구 리스트를 만들고, ID를 통해 해당 사용자 정보가 있는 컴퓨터 정보를 얻는다.  \n얻은 컴퓨터 정보 안에서 사용자 정보를 다시 탐색한다.  \n효율적 탐색을 위해서 해시테이블을 사용한다.\n\n**최적화하기**\n\n- 다른 서버에 대한 탐색을 줄인다.\n- 컴퓨터에 사용자 정보를 분배할 때, 무작위로 나누는 것이 아닌 사용자가 거주하는 나라나 시, 도, 군 등의 정보를 이용한다.\n"}}},"next":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"11dd1a4e3a3fb9c66c9aed0ca88c6c669d88bab4","text":"# 시스템 설계 및 규모 확장성 문제 4 - 캐시\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 4 - 캐시\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 캐시 : 간단한 검색 엔진으로 구현된 웹 서버를 생각해보자. 이 시스템에선 100개의 컴퓨터가 검색 요청을 처리하는 역할을 하고 있다. 예를 들어 하나의 컴퓨터 집단에 processSearch(string query)라는 요청을 보내면 그에 상응하는 검색 결과를 반환해 준다. 하지만 어떤 컴퓨터가 요청을 처리하게 될지는 그때그때 다르며, 따라서 같은 요청을 한다고 같은 컴퓨터가 처리할 거라고 장담할 수 없다. processSearch 메서드는 아주 고비용이다. 최근 검색 요청을 캐시에 저장하는 메커니즘을 설계하라. 데이터가 바뀌었을 때 어떻게 캐시를 갱신할 것인지 반드시 설명하라.\n\n## 가정을 통해 문제를 구체화하자\n\n- 필요할 때 processSearch를 호출하는 것 이외에도, 모든 쿼리는 최초로 호출된 서버에서 처리된다.\n- 캐시하고자 하는 쿼리의 수는 굉장히 크다(수백만 개)\n- 서버 간 호출은 상대적으로 빨리 처리된다.\n- 쿼리의 결과는 정렬된 URL 리스티이다. 각 원소에는 최대 50글자의 제목과 200글자의 요약문이 따라 붙는다.\n- 가장 인기 있는 쿼리의 경우 항상 캐시에 보관되어 있다.\n\n## 시스템 요구 사항을 정리하자\n\n1. 최근 검색 요청을 캐시에 저장해야 한다.\n2. 캐시를 통해 빠른 탐색이 가능해야 한다.\n3. 쿼리 결과가 변경될 경우 캐시를 변경하거나 삭제할 수 있어야 한다.\n\n## 단순하게 생각하자 - 요구사항 1, 2번\n\n단순하게 컴퓨터가 하나일 경우로 가정하여 설계해본다.\n\n빠른 탐색이 가능하려면 key-value 쌍의 자료구조인 해시맵을 사용하는 게 적절할 것 같다.  \n쿼리를 해시 처리하여 key값을 생성하고 쿼리의 결과 값을 value로 해서 해시맵에 저장하면 될 듯 싶다.\n\n첫번째 요구사항을 보면 캐시에 최신 검색 순으로 저장될 필요가 있다. 데이터를 순서대로 저장해야 한다.  \n하지만 해시맵은 데이터의 순서를 기억하기에는 적절치 못한 자료구조다.  \n순서를 위한 자료구조는 배열과 연결리스트가 있는데 최신 검색의 삽입과 오래된 검색의 삭제가 빈번하므로 연결리스트 자료구조가 적절하지 않을까?  \n그러나,,,, 연결리스트는 탐색 시 Q(N) 시간이라 빠른 탐색이 힘들다..\n\n어떻게 할까?  \n두 자료구조를 합치면 어떨까?\n\n이는 LRU 캐시를 구현하라는 것과 같다.  \nLRU는 OS의 페이지 교체 알고리즘의 하나로 최근에 가장 오랫동안 사용되지 않은 페이지를 교체하는 기법이다.\n다음은 LRU 캐시 구현 그림이다.\n\n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/4-1.jpg) <br/>\n\n## 이제 현실로 돌아와서 생각하자 - 여러 서버로 확장\n\n**방법1 - 각 서버에 별도의 캐시를 둔다**\n\n서버 1에 같은 쿼리를 2번 보내면, 두 번째 처리 결과는 캐시에서 가져온다.  \n그러나 서버 1에 보냈다가 서버 2에 보내면 서버 2는 해당 쿼리를 새로운 쿼리로 처리한다.\n\n- 장점 : 서버 간 통신이 필요없기에 상대적으로 빠르다.\n- 단점 : 같은 쿼리가 반복되도 새로운 쿼리로 인식하기 때문에 최적화를 위한 방법으로 부적절\n\n**방법2 - 각 서버에 캐시 복사본을 둔다**\n\n각 서버에 전체 캐시의 완전한 복사본을 유지하는 방법이다.  \n새로운 데이터가 캐시에 추가되는 순간 그 데이터는 모든 서버로 보내진다.  \n따라서 연결리스트와 해시테이블을 비롯한 모든 자료구조가 중복되어 저장된다.\n\n- 장점 : 어느 서버에서도 동일하게 존재하기 때문에 빈번하게 사용되는 쿼리와 실행 결과는 항상 캐시 내에 존재한다.\n- 단점1 : 캐시를 갱신할 때마다 데이터를 N개의 서로 다른 서버로 전송해야 한다는 점\n- 단점2 : 각 캐시를 저장하기 위해 N배 더 큰 공간이 필요하므로 캐시에 저장 가능한 항목의 수가 줄어든다.\n\n**방법3 - 각 서버에 캐시의 일부를 저장한다**\n\n캐시를 분할하여 각 서버에 그 일부만을 보관한다.  \n예를 들어, 서버 i가 어떤 쿼리에 대한 결과를 알고 싶다고 하자.\n\n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/4-2.jpg) <br/>\n\n## 요구 사항 3번을 해결하자\n\n- 요구사항 3 : 쿼리 결과가 변경될 경우 캐시를 변경하거나 삭제할 수 있어야 한다.\n\n캐시가 충분히 클 경우 어떤 쿼리는 너무 빈번해서 항상 캐시에 남아 있을 수 있다.  \n따라서 주기적으로 혹은 어떤 쿼리 결과가 변경되었을 때마다 캐시에 보관된 결과를 갱신할 수 있는 방법이 필요하다.\n\n쿼리의 결과가 바뀌는 순간\n\n1. URL이 가리키는 페이지 내용이 바뀔 때(URL이 가리키는 페이지가 삭제되었을 때)\n2. 페이지의 랭킹이 바뀌어서 결과의 순서가 변경될 때\n3. 특정한 쿼리에 관련있는 새로운 페이지가 등장할 때\n\n방법\n\n1. 데이터가 수정되었을 때 곧바로 캐시를 갱신할 필요가 없다. ->각 서버에 저장된 캐시를 주기적으로 탐색한 뒤 갱신된 URL에 대해서는 캐시 결과를 비운다.\n2. X분이 지나면 자동으로 캐시가 버려지도록 한다.\n\n## 관련문제\n\n[카카오 코딩테스트 문제](https://tech.kakao.com/2017/09/27/kakao-blind-recruitment-round-1/).\n\n## 캐시(난이도: 하)\n\n지도개발팀에서 근무하는 제이지는 지도에서 도시 이름을 검색하면 해당 도시와 관련된 맛집 게시물들을 데이터베이스에서 읽어 보여주는 서비스를 개발하고 있다. <br/>\n이 프로그램의 테스팅 업무를 담당하고 있는 어피치는 서비스를 오픈하기 전 각 로직에 대한 성능 측정을 수행하였는데, 제이지가 작성한 부분 중 데이터베이스에서 게시물을 가져오는 부분의 실행시간이 너무 오래 걸린다는 것을 알게 되었다.<br/>\n어피치는 제이지에게 해당 로직을 개선하라고 닦달하기 시작하였고, 제이지는 DB 캐시를 적용하여 성능 개선을 시도하고 있지만 캐시 크기를 얼마로 해야 효율적인지 몰라 난감한 상황이다.<br/>\n\n어피치에게 시달리는 제이지를 도와, DB 캐시를 적용할 때 캐시 크기에 따른 실행시간 측정 프로그램을 작성하시오.\n\n### 입력 형식\n\n- 캐시 크기(cacheSize)와 도시이름 배열(cities)을 입력받는다.\n- cacheSize는 정수이며, 범위는 0 ≦ cacheSize ≦ 30 이다.\n- cities는 도시 이름으로 이뤄진 문자열 배열로, 최대 도시 수는 100,000개이다.\n- 각 도시 이름은 공백, 숫자, 특수문자 등이 없는 영문자로 구성되며, 대소문자 구분을 하지 않는다. 도시 이름은 최대 20자로 이루어져 있다.\n\n### 출력 형식\n\n입력된 도시이름 배열을 순서대로 처리할 때, “총 실행시간”을 출력한다.\n\n### 조건\n\n- 캐시 교체 알고리즘은 LRU(Least Recently Used)를 사용한다.\n- cache hit일 경우 실행시간은 1이다.\n- cache miss일 경우 실행시간은 5이다.\n\n### 입출력 예제\n\n<table>\n<thead>\n\t<tr><th>캐시크기</th><th>도시이름</th><th>실행시간</th></tr>\n</thead>\n<tbody>\n\t<tr>\n    <td>3\t</td><td>[“Jeju”, “Pangyo”, “Seoul”, “NewYork”, “LA”, “Jeju”, “Pangyo”, “Seoul”, “NewYork”, “LA”]\t</td><td>50</td>\n    </tr>\n    <tr>\n<td>3\t</td><td>[“Jeju”, “Pangyo”, “Seoul”, “Jeju”, “Pangyo”, “Seoul”, “Jeju”, “Pangyo”, “Seoul”]</td>\t<td>21</td>\n</tr>\n<tr>\n<td>2\t</td><td>[“Jeju”, “Pangyo”, “Seoul”, “NewYork”, “LA”, “SanFrancisco”, “Seoul”, “Rome”, “Paris”, “Jeju”, “NewYork”, “Rome”]</td><td>\t60</td>\n</tr>\n<tr>\n<td>5</td><td>\t[“Jeju”, “Pangyo”, “Seoul”, “NewYork”, “LA”, “SanFrancisco”, “Seoul”, “Rome”, “Paris”, “Jeju”, “NewYork”, “Rome”]</td><td>\t52</td>\n</tr>\n<tr>\n<td>2</td><td>\t[“Jeju”, “Pangyo”, “NewYork”, “newyork”]</td>\t<td>16</td>\n</tr>\n<tr>\n<td>0\t</td><td>[“Jeju”, “Pangyo”, “Seoul”, “NewYork”, “LA”]\t</td><td>25</td>\n</tr>\n</tbody>\n</table>\n\n```java\nimport java.util.*;\npublic class Cache {\n\tprivate int cacheSize;\n\tprivate HashMap<String, Node> map;\n\tprivate LinkedList<Node> list;\n\tprivate int time;\n\n\tpublic Cache(int cacheSize) {\n\t\tthis.cacheSize = cacheSize;\n\t\tmap = new HashMap<String, Node>();\n\t\tlist = new LinkedList<Node>();\n\t\ttime = 0;\n\t}\n\n\tpublic void insertResults(String city) {\n\t\tcity = city.toLowerCase();\n\t\tif (map.containsKey(city)) {\n\t\t\ttime+=1;\n\t\t\tNode node = map.get(city);\n\t\t\tlist.remove(node);\n\t\t\tlist.addFirst(node);\n\t\t\treturn;\n\t\t}\n\n\t\ttime+=5;\n\t\tNode node = new Node(city);\n\t\tmap.put(city, node);\n\t\tlist.addFirst(node);\n\n\t\tif (list.size() > cacheSize) {\n\t\t\tNode lastNode = list.removeLast();\n\t\t\tmap.remove(lastNode.cityName);\n\t\t}\n\t}\n\n\tpublic void printCache() {\n\t\tIterator<Node> i = list.iterator();\n\t\twhile (i.hasNext()) {\n\t\t\tSystem.out.print(i.next().cityName + \" \");\n\t\t}\n\t}\n\n\tpublic int getTime() {\n\t\treturn time;\n\t}\n\n\tclass Node {\n\t\tString cityName;\n\t\tNode next;\n\n\t\tpublic Node(String cityName) {\n\t\t\tthis.cityName = cityName;\n\t\t\tthis.next = null;\n\t\t}\n\t}\n\n\n}\n```\n\n```java\npublic class LRUQuestion {\n\tpublic static void main(String[] args) {\n\n\t\tString[] cities1 = {\"Jeju\", \"Pangyo\", \"Seoul\", \"NewYork\", \"LA\", \"Jeju\", \"Pangyo\", \"Seoul\", \"NewYork\", \"LA\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(3,cities1));\n\t\tString[] cities2 = {\"Jeju\", \"Pangyo\", \"Seoul\", \"Jeju\", \"Pangyo\", \"Seoul\", \"Jeju\", \"Pangyo\", \"Seoul\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(3,cities2));\n\t\tString[] cities3 = {\"Jeju\", \"Pangyo\", \"Seoul\", \"NewYork\", \"LA\", \"SanFrancisco\", \"Seoul\", \"Rome\", \"Paris\", \"Jeju\", \"NewYork\", \"Rome\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(2,cities3));\n\t\tString[] cities4 = {\"Jeju\", \"Pangyo\", \"Seoul\", \"NewYork\", \"LA\", \"SanFrancisco\", \"Seoul\", \"Rome\", \"Paris\", \"Jeju\", \"NewYork\", \"Rome\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(5,cities4));\n\t\tString[] cities5 = {\"Jeju\", \"Pangyo\", \"NewYork\", \"newyork\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(2,cities5));\n\t\tString[] cities6 = {\"Jeju\", \"Pangyo\", \"Seoul\", \"NewYork\", \"LA\"};\n\t\tSystem.out.println(\"실행시간 : \" + testCache(0,cities6));\n\t}\n\n\tpublic static int testCache(int cacheSize, String[] cities) {\n\t\tCache cache = new Cache(cacheSize);\n\t\tfor (String city : cities)\n\t\t\tcache.insertResults(city);\n\n\t\treturn cache.getTime();\n\t}\n}\n```\n"}}}},"pageContext":{"id":"715125ef37493c20558b7c22e3a63779c2d38594","previousPostId":"725f6823a549cb3bd4d8fddd15021a218c438de0","nextPostId":"11dd1a4e3a3fb9c66c9aed0ca88c6c669d88bab4"}},"staticQueryHashes":["2685952063","2841359383"]}