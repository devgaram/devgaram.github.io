{"componentChunkName":"component---src-templates-blog-post-js","path":"/725f6823a549cb3bd4d8fddd15021a218c438de0","result":{"data":{"site":{"siteMetadata":{"title":"보노보노의 평화로운 개발 이야기"}},"current":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"725f6823a549cb3bd4d8fddd15021a218c438de0","text":"# [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 소셜 네트워크 : 페이스북이나 링크드인과 같은 대규모 소셜 네트워크를 위한 자료구조는 어떻게 설계하겠는가? 두 사람 사이의 최단 경로를 보여주는 알고리즘은 어떻게 설계하겠는가? (가령, 나->밥->수잔->제이슨->당신)\n\n## 내풀이\n\n'나'를 기준으로 '나'의 친구들을 연결할 필요가 있고, '친구'의 친구들을 연결할 필요가 있다.  \n각 사용자를 '노드'로 정의하고 관계를 '에지'로 정의한다고 하면 자료구조로 그래프를 사용하는 게 적절하다고 생각한다.  \n사용자 간의 경로 탐색은 너비우선탐색(BFS)로 하는 것이 적절하다고 생각한다.\n'나'를 기준으로 동심원을 그리며 찾는 것이 깊이우선탐색(DFS)보다 낫다.\nDFS는 '노드'를 기준으로 방문하지않은 노드 끝까지 갔다가 돌아가는 식으로 탐색하므로 최단경로가 아닐 수도 있다.\n\n## 책풀이\n\n## 단계1 : 문제를 단순화하기 - 수백만이 아닌 10명의 사용자로 생각해보기\n\n각 사용자를 노드, 친구 관계를 간선으로 설정하여 하나의 그래프를 만들 수 있다.  \n두 사용자 간의 경로는 한 사용자에서 시작해서 너비 우선 탐색을 돌려보면된다.\n혹은 양방향 너비 우선 탐색을 할 수도 있다.  \n하나는 출발지에서, 나머지 하나는 도착지에서 시작해서 너비 우선 탐색 두 개를 동시에 돌리는 것을 말한다.  \n두 탐색이 어느 지점에서 충돌하는 순간 경로를 찾은 것이다.\n\n**깊이우선탐색을 사용하지 않는 이유는?**  \n깊이 우선 탐색은 단순히 경로 하나를 찾기 때문이고, 이 경로가 가장 짧은 경로가 아닐 수도 있다.  \n또한, 경로 하나를 찾는 과정도 비효율적이다. 두 사용자가 1촌 관계라 하더라도 하위 트리에 존재하는 수백만 개의 노드를 탐색하게 될 수 있기 때문이다.\n\n**구현방법**  \n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-1.jpg) <br/>\n![2](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-2.jpg) <br/>\n![3](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-3.jpg) <br/>\n![4](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-4.jpg) <br/>\n\n양방향 너비 우선 탐색이 일반 너비 우선 탐색보다 빠르다.  \nS와 D가 친구 C를 공유할 때, (각 사용자는 K명의 친구가 있다, q는 경로의 길이)\n\n- 일반적인 너비 우선 탐색으로 S -> D로 가려면 대략 K + K\\*K개의 노드를 거쳐야 한다. = Q(K<sup>q</sup>)\n- 양방향 너비 우선 탐색은 S 친구 K, D친구 K로 2K 노드만 거치면 된다. = Q(K<sup>q/2</sup>)\n\n단, 양방향 너비 우선 탐색은 시작 지점과 도착 지점 모두 접근 가능할 때에나 사용 가능하다.\n\n## 단계2 : 수백만 사용자의 처리\n\n링크드인이나 페이스북 규모의 서비스를 만들 때에는 컴퓨터 하나만으로는 부족하다.  \n다시 말해 Person을 위와 같이 단순하게 설계해서는 제대로 동작하지 않을 것이라는 뜻이다.  \n우리가 찾는 '친구'는 같은 서버에 있지 않을 수도 있다.  \n따라서 ID로 구성되는 친구 리스트를 만들고, ID를 통해 해당 사용자 정보가 있는 컴퓨터 정보를 얻는다.  \n얻은 컴퓨터 정보 안에서 사용자 정보를 다시 탐색한다.  \n효율적 탐색을 위해서 해시테이블을 사용한다.\n\n**최적화하기**\n\n- 다른 서버에 대한 탐색을 줄인다.\n- 컴퓨터에 사용자 정보를 분배할 때, 무작위로 나누는 것이 아닌 사용자가 거주하는 나라나 시, 도, 군 등의 정보를 이용한다.\n"}}},"previous":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"a1f625269928ae850f3014fdc0614633e4ee091c","text":"# 시스템 설계 및 규모 확장성 문제 1 - 중복 URL\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 1 - 중복 URL\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 중복 URL : 100억 개의 URL이 있다. 중복된 문서를 찾으려면 어떻게 해야 하는가? 여기서 '중복'이란 '같은 URL'이라는 뜻이다.\n\n## 내풀이\n\n만약 100억 개의 URL을 저장할 수 있는 충분한 공간이 있다면, 리스트를 정렬한 후 중복된 값 찾으면 될 것 같다.  \n아니면 100억 개의 URL을 해시테이블에 저장하는 전처리 과정을 하면 전처리 과정 중에도 중복된 문서를 찾을 수 있고\n그 후 데이터가 추가될 때도 쉽게 중복 여부를 확인할 수 있을 것 같다.\n\n## 책풀이\n\n## 1단계 : 합당한 가정을 세운다.\n\n책은 100억 개의 URL을 처리하기위한 공간을 계산하기위해 다음과 같은 합당한 가정을 세운다.\n\n- 각 URL이 평균적으로 100개의 문자로 구성되어 있고 각 문자는 4바이트라고 가정한다.\n- 100(문자) _ 4(bytes) _ 100억(url개수) = 4,000,000,000,000 bytes = 4 \\* 10<sup>12</sup> = 4TB\n- 즉, 100억 개의 URL을 처리하기위해서는 4TB 정도의 메모리 공간이 필요하다.\n\n## 2단계 : 현실적 제약을 무시한다.\n\n모든 데이터를 메모리에 보관할 수 있다고 가정한 후 문제에 접근한다.\n\n이미 살펴본 URL에 대해 true를 반환하는 해시테이블을 사용하여 문제를 해결할 수 있다.  \n리스트를 정렬하는 방식은 시간도 더 들고 장점도 없다.\n\n## 3단계 : 현실로 돌아온다.\n\n4TB의 데이터를 메모리(RAM)에 전부 올릴 수 없는 상황에서 어떻게 해야하는지 생각한다.\n\n**해법 #1 : 디스크 저장**\n\n각 URL을 .txt 파일에 저장한다.  \n.txt 파일의 크기는 1GB(10<sup>9</sup>)로 4TB URL을 저장하기위해서는 4000개의 파일이 필요하다.  \nx = hash(u) % 4000로 저장할 .txt 파일을 결정한다.  \n같은 해시값을 갖는 URL은 같은 파일에 저장된다.  \n각 파일을 메모리에 올려 URL의 해시테이블을 생성한 다음에 중복이 존재하는 지 확인하면 된다.\n\n**해법 #2 : 데이터를 여러 서버에 분할**\n\n본질적으로는 해법1과 같으나, 여러 서버를 사용한다는 차이가 있다.  \nURL을 .txt라는 파일에 저장하는 대신 서버 x에 전송하는 것이다.\n\n- 장점 : 병렬처리가능\n- 단점 : 4000개의 서버가 완벽 동작해야함(비현실적)\n"}}},"next":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"715125ef37493c20558b7c22e3a63779c2d38594","text":"# 시스템 설계 및 규모 확장성 문제 3 - 웹 크롤러\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 3 - 웹 크롤러\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 웹 크롤러 : 웹에 있는 데이터를 긁어 오는 크롤러를 설계할 때, 무한루프에 빠지는 일을 방지하려면 어떻게 해야 하는가?\n\n## 무한루프는 어떻게 발생하는가?\n\n단순히 웹의 링크에 의해 만들어지는 그래프로 볼 경후, 사이클이 존재하면 무한루프가 발생할 수 있다.  \n따라서 무한루프를 막으려면 사이클을 탐지해야 한다.  \n그러기 위해선 해시테이블을 두고 이미 방문한 페이지 v의 hash[v] 값을 true로 바꿔줘야 한다.  \n이 해법은 웹을 너비 우선으로 탐색한다는 것을 의미한다.\n\n## 페이지 v를 방문한다는 것의 의미\n\n1. 단순히 URL 기준으로 판단해야 할까?\n2. 페이지 내용에 따라 방문 여부를 확인해야 할까?\n\n1번의 경우는 URL의 파라미타 값이 달라졌을 때 실제로 페이지는 달라지지 않을 때를 생각해야한다.  \n2번의 경우 같은 페이지라 할지라도 내용이 무작위로 생성된다면 다른 페이지라고 해야하는 지를 생각해봐야한다.  \n즉, 이 페이지가 저 페이지와 '다른' 페이지인지 판단하는 완벽한 방법은 없는 셈이다.\n\n이 문제를 해결하는 방법은 페이지 내용과 URL을 토대로 페이지 간의 유사성을 가늠해 보는 것이다.\n\n- 크롤러가 탐색해야 하는 항목들을 데이터베이스에 저장해 둔다.\n- 탐색 우선순위가 가장 높은 페이지를 고른다.\n- 페이지를 열어 해당 페이지의 특정한 섹션과 URL을 토대로 시그니처를 생성한다.\n- 데이터베이스 쿼리를 통해 해당 시그니처의 페이지가 최근에 탐색된 적 있는지 살핀다.\n- 만일 해당 시그니처를 갖는 페이지가 최근에 탐색된 적이 있으면 해당 페이지의 우선순위를 낮춰서 데이터베이스에 추가한다.\n- 그렇지 않다면 해당 페이지를 탐색하고, 그 페이지에 연결된 링크를 데이터베이스에 추가한다.\n"}}}},"pageContext":{"id":"725f6823a549cb3bd4d8fddd15021a218c438de0","previousPostId":"a1f625269928ae850f3014fdc0614633e4ee091c","nextPostId":"715125ef37493c20558b7c22e3a63779c2d38594"}},"staticQueryHashes":["2685952063","2841359383"]}