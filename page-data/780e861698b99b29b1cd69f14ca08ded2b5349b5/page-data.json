{"componentChunkName":"component---src-templates-blog-post-js","path":"/780e861698b99b29b1cd69f14ca08ded2b5349b5","result":{"data":{"site":{"siteMetadata":{"title":"보노보노의 평화로운 개발 이야기"}},"current":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"780e861698b99b29b1cd69f14ca08ded2b5349b5","text":"# AWS 연습하자 3탄 - Jenkins와 S3 버킷 & AWS codeDeploy 연동으로 배포하기\n\n- Title : AWS 연습하자 3탄 - Jenkins와 S3 버킷 & AWS codeDeploy 연동으로 배포하기\n- Date : 2020-02-26\n- Category: Infra\n\n> AWS 연습하자 시리즈\n>\n> - [AWS 연습하자 1탄 - AWS EC2 인스턴스에 Jenkins 서버 구축하기](/post/2020-02-24-how-to-use-aws)\n> - [AWS 연습하자 2탄 - Jenkins와 Github 연동](/post/2020-02-25-how-to-use-aws)\n\nAWS 연습하기 3탄에서는 AWS S3와 Aws Codedeploy로 자동 배포 환경을 구축하는 과정을 다루겠습니다.\n\n# 배포 서버인 EC2 인스턴스 생성\n\n[AWS 연습하자 1탄](/post/2020-02-24-how-to-use-aws)의 AWS EC2 인스턴스 생성하기 부분을 진행하여 인스턴스를 생성하고 오세요! 저는 Name 태그에 blog-server로 인스턴스를 생성했습니다.\n\n# AWS Code Deploy 계정 생성\n\n여기서 생성한 계정을 가지고 Jenkins와 blog-server 인스턴스에서 설정을 진행할 것입니다.\n\n**[AWS IAM 콘솔](https://console.aws.amazon.com/iam/) -> 사용자 탭 -> 사용자 추가** 를 클릭합니다.\n\n사용자 이름을 입력하고 액세스 유형은 프로그래밍 방식 액세스를 선택합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/29.PNG)\n\n해당 계정이 사용할 수 있는 정책으로는 CodeDeploy와 S3 권한을 할당 받겠습니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/30.PNG)\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/31.PNG)\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/32.PNG)\n\n.csv 다운로드 버튼을 클릭하여 비밀키를 잘 보관해둡니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/33.PNG)\n\n# AWS S3 버킷 생성\n\n**[AWS S3 콘솔](https://s3.console.aws.amazon.com/s3/) -> 버킷 만들기** 를 클릭합니다.\n\n버킷 이름이 blog-server-bucket으로 하고 리전이 서울인지 확인합니다. 추가 옵션 없이 다음을 계속하여 버킷 생성을 완료합니다.\n\n# IAM Role 생성\n\nblog-server EC2와 CodeDeploy에게 신뢰할 수 있는 권한을 설정하여 젠킨스가 정상적으로 배포할 수 있게 하겠습니다.\n\n> CodeDeploy가 EC2 접근할 수 있도록 설정하는 것!\n\n**[AWS IAM 콘솔](https://console.aws.amazon.com/iam/) -> 역할 -> 역할 만들기** 를 클릭합니다.\n\nAWS 서비스를 누른 후 이 역할을 사용할 서비스 선택에서 **EC2**를 선택합니다. 권한 정책으로 **AmazonEC2RoleforAWSCodeDeploy** 를 체크한 후 다음: 태그로 넘어갑니다. 태그는 건너 뛰고 역할 이름은 **blog-server-EC2CodeDeployRole**을 입력한 후 역할 만들기를 클릭하겠습니다.\n\n지금 만든 역할은 blog-server EC2에 IAM 역할로 설정할 것입니다.\n\n마찬가지로 CodeDeploy도 역할을 생성하겠습니다.\n\n**[AWS IAM 콘솔](https://console.aws.amazon.com/iam/) -> 역할 -> 역할 만들기** 를 클릭합니다.\n\nAWS 서비스를 누른 후 이 역할을 사용할 서비스 선택에서 **CodeDeploy**를 선택합니다. 사용 사례 선택 섹션에서도 **CodeDeploy**를 선택합니다. 권한 정책으로 **AWSCodeDeployRole** 를 하나이므로 그냥 확인하고 다음: 태그로 넘어갑니다. 태그는 건너 뛰고 역할 이름은 **blog-server-CodeDeployServiceRole**을 입력한 후 역할 만들기를 클릭하겠습니다.\n\n# EC2에 AWS 역할 적용하기\n\nEC2 콘솔로 이동한 후 아래와 같이 IAM 역할 연결/바꾸기 를 선택합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/34.PNG)\n\n아까만든 **blog-server-EC2CodeDeployRole** 을 선택한 후 적용합니다.\n\n# EC2 AWS CodeDeploy Agent 설치 및 설정\n\n이제 blog-server 인스턴스에 CodeDeploy Agent를 설치하겠습니다.\n\n인스턴스로 접속한 후 패키지 업데이트를 수행합니다.\n\n```\nssh -i my-key-pair.pem ec2-user@퍼블릭DNS\nsudo yum update -y\n```\n\naws cli를 설치하겠습니다.\n\n```\nsudo yum install awscli\n```\n\n에이전트 설치 후 aws 설정을 하겠습니다.\n\n```\nsudo aws configure\n```\n\nAWS Access Key ID, AWS Secret Acecess Key ID는 사용자 생성할 때 받은 CSV를 보고 입력합니다.\n\n추가 정보는 아래와 같이 입력 후 엔터칩니다.\nDefault region name: ap-northeast-2\nDefault output format: json\n\n계속 설치를 진행하겠습니다.\n\n```\ncd /home/ec2-user\n\n# agent 파일 다운로드\naws s3 cp s3://aws-codedeploy-ap-northeast-2/latest/install . --region ap-northeast-2\n\n# 실행권한 추가\nchmod +x ./install\n\n# 설치 진행\nsudo ./install auto\n\n# agent가 실행 중인지 확인 PID가 나오면 정상적으로 실행 중인 상태입니다.\nsudo service codedeploy-agent status\n```\n\n만약 **sudo ./install auto** 커맨드 실행 결과 **/usr/bin/env: ruby: No such file or directory**가 나온다면 루비를 설치해야합니다. 아래와 같이 실행 후 다시 설치를 진행합니다.\n\n```\nsudo yum install ruby -y\n```\n\n추가로 재 부팅시 자동으로 code deploy agent가 실행될 수 있도록 스크립트를 생성하고 권한을 주겠습니다.\n\n```\n# 아래 스크립트를 입력합니다.\nsudo vim /etc/init.d/codedeploy-startup.sh\n\nsudo chmod +x /etc/init.d/codedeploy-startup.sh\n```\n\n> #!/bin/bash  \n> echo 'Starting codedeploy-agent'  \n> sudo service codedeploy-agent restart\n\n# nginx와 Docker로 무중단 배포하기\n\n## 1) 도커, 도커컴포즈 설치 및 프로젝트 파일 생성\n\n도커 컨테이너 위에서 애플리케이션을 구동하기위해서 ec2에 도커와 도커컴포즈를 설치합니다.\n\n```\nsudo yum install docker\n\n# 도커 컴포즈 다운로드\n$ sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n\n# 실행 권한 주기\n$ sudo chmod +x /usr/local/bin/docker-compose\n\n# 설치 완료됐는 지 확인하기\n$ docker-compose --version\n\n# bash: docker-compose: command not found 문구가 나오면 아래 커맨드 실행하기\n$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n```\n\n잠시 배포에 대해 짚고 넘어가겠습니다. 뒤에서 실습을 진행하겠지만, AWS Code Deploy에서 배포한 파일은 /home/ec2-user/build 에 복사되게 할 것입니다.\n\n배포 후 /home/ec2-user/build 이 폴더에는 Dockerfile 과 docker-compose.yml 파일이 존재할것이고 이를 이용해 컨테이너에 서버를 올릴 것입니다.\n\n혹시 docker ps 해봤더니 **Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?** 에러가 떴다면 docker service가 실행이 안된 것이므로 아래와 같이 명령을 내리겠습니다. [도커 설치 가이드](https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user)를 참고했습니다.\n\n```\nsudo groupadd docker\nsudo usermod -aG docker $USER\nsudo newgrp docker\n\n# 아래 커맨드 실행 결과 상태가 active여야 정상적인 것!\nsudo systemctl status docker\nsudo systemctl start docker\nsudo systemctl enable docker\n```\n\n이제 프로젝트에 Dockerfile과 docker-compose 파일을 작성하겠습니다.\n\n> 도커에 대해 기본지식이 필요합니다. 나중에 도커 관련 포스팅도 작성하겠습니다..!\n\n프로젝트 루트에 다음과 같이 Dockerfile을 작성합니다.\n\n```\n# 로컬과 같은 버전\nFROM node:12.14\n\n# 도커 이미지 만든 사람\nLABEL maintainer=\"joingaram@gmail.com\"\n\n# 3000포트로 도커 데몬에 연결\nEXPOSE 3000\n\n# 작업 디렉토리 & 자동으로 작업 디렉토리로 현재 위치 변경\nWORKDIR /usr/src/app\n\nCOPY package.json .\nCOPY yarn.lock .\nRUN yarn cache clean & yarn install --network-timeout 100000\nCOPY . .\n\nCMD [\"yarn\", \"start\"]\n\n```\n\n프로젝트 루트에 docker-compose.blue.yml 파일과 docker-compose.green.yml 파일을 생성한 후 아래와 같이 입력합니다. 포트만 3001, 3002로 다릅니다.\n\ndocker-compose.blue.yml\n\n```\nversion: \"3.7\"\nservices:\n  blog-server:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    volumes:\n      - .:/usr/src/app\n    ports:\n      - \"3001:3000\"\n```\n\ndocker-compose.green.yml\n\n```\nversion: \"3.7\"\nservices:\n  blog-server:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    volumes:\n      - .:/usr/src/app\n    ports:\n      - \"3002:3000\"\n```\n\n## 2) nginx로 로드밸런싱 설정\n\n우선 nginx를 설치합니다. 프록시 서버로 두 개의 도커 컨테이너를 로드밸런싱하는 역할을 담당할 것입니다.\n\n```\nsudo amazon-linux-extras install nginx1\nsudo service nginx start\n\n# 잘 실행되었는지 확인\nps -ef | grep nginx\n```\n\n이제 **nginx 설정 파일 수정** 작업을 하겠습니다.\n\n```\nsudo vi /etc/nginx/nginx.conf\n```\n\n다음과 같이 수정한 후 저장합니다.\n\n```\n# Load Balancing\nupstream blog-server {\n  least_conn;\n  server 127.0.0.1:3001 weight=5 max_fails=3 fail_timeout=10s;\n  server 127.0.0.1:3002 weight=10 max_fails=3 fail_timeout=10s;\n}\n\nserver {\n  listen 80;\n  server_name 서버 아이피; # 세미콜론 붙여주셔야 합니다.\n  location / {\n    proxy_pass http://blog-server;\n  }\n}\n```\n\n잘 설정했는 지 확인하고 nginx를 재시작합니다.\n\n```\n\nsudo nginx -t\nsudo service nginx restart\n```\n\n> [생활코딩nginx](https://opentutorials.org/module/384/4328)\n>\n> - Nginx는 4개의 로드밸런싱 메서드를 제공합니다. 그중 least_conn 은 연결이 가장 작은 서버로 요청을 보냅니다.\n> - weight=n : 업스트림 서버의 비중을 나타냅니다. 이 값을 2로 설정하면 그렇지 않은 서버에 비해 두배 더 자주 선택됩니다.\n> - max_fails=n : n으로 지정한 횟수만큼 실패가 일어나면 서버가 죽은 것으로 간주합니다.\n> - fail_timeout=n : max_fails가 지정된 상태에서 이 값이 설정만큼 서버가 응답하지 않으면 죽은 것으로 간주합니다.\n\n# Jenkins 배포 설정\n\n우선 Pipeline AWS STEP과 AWS Codedeploy 플러그인을 설치해줍니다. Pipeline AWS STEP은 S3로 소스 전송할 때, AWS Codedeploy로는 S3 버킷의 코드를 인스턴스에 배포하도록 설정하겠습니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/22.PNG)\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/25.PNG)\n\n각 플러그인 사용방법\n\n- [Pipeline AWS STEP](https://github.com/jenkinsci/pipeline-aws-plugin#deployapi)\n- [AWS Codedeploy](https://github.com/jenkinsci/aws-codedeploy-plugin)\n\n## 1) S3 UPLOAD 작성\n\n먼저 AWS 접근을 위한 설정을 하겠습니다.\n\n**젠킨스 메인 -> Credentials -> System -> Global credentials -> Add Credentials** 를 차례로 클릭합니다.\n\nKind는 AWS Credentials를 선택하고 Access key와 secret key는 위에서 생성한 csv 파일을 보고 입력합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/23.PNG)\n\nOK 클릭 후 클릭해보면 아래와 같이 ID를 볼수 있습니다. 파이프라인 작성 시에 사용해야하므로 저장해둡니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/24.PNG)\n\nAWS 연습하기 2탄에서 작업했던 파이프라인을 아래와 같이 수정합니다.\n\n- credentials에는 위에서 복사한 ID를 입력합니다.\n- Bucket에는 아까 생성한 S3 버킷 입력을 입력합니다.\n\n```\npipeline {\n   agent any\n\n   environment {\n       S3PATH = \"${env.JOB_NAME}\"\n   }\n   tools {\n      nodejs \"node\"\n   }\n\n   stages {\n      stage('Build') {\n         steps {\n            git 'https://github.com/devgaram/express-project-blog.git'\n         }\n      }\n\n      stage('Install dependencies') {\n          steps {\n              sh 'npm install -g yarn'\n              sh 'yarn install'\n          }\n      }\n      stage('Test') {\n          steps {\n              echo 'test..'\n              // yarn test\n          }\n      }\n      stage('Upload S3') {\n          steps {\n              echo 'Upload S3'\n              withAWS(credentials: '667cec8d-baa7-497f-b2db-2d424c121a22') {\n                s3Upload(file: '.', bucket: 'blog-server-bucket', path: \"${S3PATH}\", excludePathPattern: '**/node_modules/**, **/.git/**')\n              }\n          }\n      }\n      stage('Deploy') {\n          steps {\n              echo 'deploy'\n          }\n      }\n   }\n   post {\n        success {\n            echo 'successed'\n        }\n        failure {\n            echo 'failed'\n        }\n   }\n}\n```\n\n**Apply -> 저장 -> Build Now** 를 클릭하면 잘 실행될 것입니다.\n\n## 2) AWS CodeDeploy 설정\n\n**Jenkins 메인 -> blog-server 아이템 -> Pipeline Syntax -> Snippet Generator**를 선택합니다.\n\nSnippet Generators는 파이프라인 스크립트 생성에 도움을 주는 녀석입니다. 얘를 이용해 AWS CodeDeploy를 이용한 배포를 설정하겠습니다.\n\n**Steps 섹션 -> Sample Step - step:General Build Step 선택 -> Build Step - Deploy an application to AWS CodeDeploy 선택** 을 진행합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/26.PNG)\n\n- AWS CodeDeploy Application Name: EC2 인스턴스 이름\n- AWS CodeDeploy Deployment Group: CodeDeploy 그룹 명\n- AWS CodeDeploy Deployment Config: 배포 환경, 여기선 CodeDeployDefault.OneAtATime\n- AWS Region: AP_NORTHEAST_2\n- S3 Bucket: S3 버킷 이름\n\nUse Access/Secret keys 라디오 버튼을 선택하여 csv로 저장했던 내용을 입력해줍니다.\n\n마지막으로 Generate Pipeline Script 버튼을 클릭하면 나오는 텍스트를 복사합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/27.PNG)\n\n최종적으로 파이프라인을 아래와 같이 구성됩니다.\n\n```\npipeline {\n   agent any\n\n   environment {\n       S3PATH = \"${env.JOB_NAME}\"\n       AWS_SECRET_ACCESS_KEY = \"${env.AWS_SECRET_ACCESS_KEY}\"\n   }\n   tools {\n      nodejs \"node\"\n   }\n\n   stages {\n      stage('Build') {\n         steps {\n            git 'https://github.com/devgaram/express-project-blog.git'\n         }\n      }\n\n      stage('Install dependencies') {\n          steps {\n              sh 'npm install -g yarn'\n              sh 'yarn install'\n          }\n      }\n      stage('Test') {\n          steps {\n              echo 'test..'\n              // yarn test\n          }\n      }\n      stage('Upload S3') {\n          steps {\n              echo 'Upload S3'\n              withAWS(credentials: '667cec8d-baa7-497f-b2db-2d424c121a22') {\n                s3Upload(file: '.', bucket: 'blog-server-bucket', path: \"${S3PATH}\", excludePathPattern: '**/node_modules/**, **/.git/**')\n              }\n          }\n      }\n      stage('Deploy') {\n          steps {\n              echo 'deploy'\n              step([$class: 'AWSCodeDeployPublisher', applicationName: 'blog-server', awsAccessKey: 'AKIASDBC2NNSJWD4F76B', awsSecretKey: \"${AWS_SECRET_ACCESS_KEY}\", credentials: 'awsAccessKey', deploymentConfig: 'CodeDeployDefault.OneAtATime', deploymentGroupAppspec: false, deploymentGroupName: 'blog-server-CodeDeploy-group', excludes: '', iamRoleArn: '', includes: '**', proxyHost: '', proxyPort: 0, region: 'ap-northeast-2', s3bucket: 'blog-server-bucket', s3prefix: '', subdirectory: '', versionFileName: '', waitForCompletion: false])\n          }\n      }\n   }\n   post {\n        success {\n            echo 'successed'\n        }\n        failure {\n            echo 'failed'\n        }\n   }\n}\n\n\n```\n\n## 3) AWS Deploy 설정 파일\n\nAWS CodeDeploy는 프로젝트 루트에 있는 appspec.yml를 이용하여 배포를 진행합니다. 자세한 내용은 [aws 가이드](https://docs.aws.amazon.com/ko_kr/codedeploy/latest/userguide/reference-appspec-file.html#appspec-reference-server)에서 확인하세요.\n\n프로젝트 루트에 appspec.yml 파일 생성 후 아래와 같이 입력합니다. AWS CodeDeploy가 ec2의 /home/ec2-user/build/ 위치에 S3 버킷에 있는 코드를 옮기도록 설정했습니다. 배포 후에는 execute-deploy.sh 작업을 통해 도커 컨테이너를 올릴 것입니다.\n\n```\nversion: 0.0\nos: linux\nfiles:\n  - source:  /\n    destination: /home/ec2-user/build/\nhooks:\n  AfterInstall: # 배포 후\n    - location: execute-deploy.sh\n      timeout: 180\n```\n\nexecute-deploy.sh\n\n```\n#!/bin/bash\ncd /home/ec2-user/build\nchmod +x ./deploy.sh\n./deploy.sh > /dev/null 2> /dev/null < /dev/null &\n```\n\n현재 블루 컨테이너가 돌고 있다면 그린 컨테이너를 구동한 후 블루 컨테이너를 종료합니다. 이 방법을 통해 무중단 배포를 할 수 있는 것입니다. 아래와 같이 작성합니다.\n\ndeploy.sh\n\n```\n#!/bin/bash\n\nDOCKER_APP_NAME=blog-server\n\nEXIST_BLUE=$(docker-compose -p ${DOCKER_APP_NAME}-blue -f docker-compose.blue.yml ps | grep Up)\n\nif [ -z \"$EXIST_BLUE\" ]; then\n\techo \"blue up\"\n\tdocker-compose -p ${DOCKER_APP_NAME}-blue -f docker-compose.blue.yml up -d\n\n\tsleep 10\n\n\tdocker-compose -p ${DOCKER_APP_NAME}-green -f docker-compose.green.yml down\nelse\n\techo \"green up\"\n\tdocker-compose -p ${DOCKER_APP_NAME}-green -f docker-compose.green.yml up -d\n\n\tsleep 10\n\n\tdocker-compose -p ${DOCKER_APP_NAME}-blue -f docker-compose.blue.yml down\nfi\n```\n\n자 이제 실제로 커밋 푸시하면 배포까지 완료되는 것을 볼 수 있습니다!\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/28.PNG)\n\n> 추가로 해야할 것\n>\n> - S3에 왜 node_modules랑 .git도 올라가는 거지..? 분명 제외시켰는 데..\n\n참고\n\n- [기억보단 기록을](https://jojoldu.tistory.com/265)\n- https://velog.io/@jeff0720/Travis-CI-AWS-CodeDeploy-Docker-%EB%A1%9C-%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94-%EB%B0%8F-%EB%AC%B4%EC%A4%91%EB%8B%A8-%EB%B0%B0%ED%8F%AC-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0-2\n- https://medium.com/faun/create-a-continuous-delivery-pipeline-using-jenkins-gitlab-github-and-deploy-on-aws-ec2-with-3aaadf073196\n"}}},"previous":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"476dc1d82d78ebda7412a9be6dbf3ccf0973fbae","text":"# Union-Find란?\n\n- Title : Union-Find란?\n- Date : 2020-02-27\n- Category: Algorithm\n\n## Why?\n\n[1717번: 집합의 표현](https://www.acmicpc.net/problem/1717)\n\n오 쉽네?😁 라고 생각하며 빠르게 풀고 제출했지만 **메모리 초과**가 발생했다. 아무래도 n\\*n 이차원 배열을 자료구조로 선택한 것이 원인인 듯 싶어 일차원 배열로 바꿔서 다시 풀어봤다. n크기의 배열에서 0→n 까지 반복을 돌려서 v[i]가 b면 a로 값을 바꿔주는 식으로 했다. 이번엔 메모리 초과는 안 떴지만 **시간 초과**가 떴다..두둥 😢🤢 어떻게 풀어야 하는 거지?\n\n## Union-Find란?\n\n> 여러 노드가 존재할 때 선택한 두 개의 노드가 같은 그래프에 속하는 지 판별할 때 사용하는 대표적인 그래프 알고리즘으로 합집합 찾기라는 의미를 가진다.\n\nDisjoint Set(디스조인트 셋)을 표현할 때 사용하는 자료구조로 **공통 원소가 없는 부분 집합**들로 나눠진 원소들에 대한 정보를 저장하는 자료구조다. 예를 들어 {1}, {2,3} , {4,5,6}, {7} 와 같이 공통 원소가 없는 부분 집합을 저장할 때 사용한다. 이 상황을 표현하기 위해 초기화, Union(합치기) 연산과 Find(찾기) 연산을 지원해야해서 Union-Find라고 부르게 되었다.\n\n- 초기화: N개의 원소가 각각의 집합에 포함되어 있도록 초기화한다. 예시) N=5면 {0}, {1}, {2}, {3}, {4}, {5} 로 초기화\n- Union연산: 두 원소 a, b가 주어질 때, 이들이 속한 두 집합을 하나로 합친다.\n- Find연산: 어떤 원소 a가 주어질 때, 이 원소가 속한 집합을 반환한다.\n\n## Union-Find 구현\n\n> 실제 구현은 주로 트리구조를 이용한다. 배열은 왜 사용하지 않는지? 트리를 사용할 때의 장점은 무엇인지? 알아보자\n\n### 배열로 표현\n\n1차원 배열로 집합을 표현한다. 예를 들어 Array[i]: i번 원소가 속하는 집합의 번호 라 해보자.\n\n- 초기화: Array[i] = i 로 각각 다른 집합 번호로 초기화한다.\n- Union연산 O(N): 두 집합을 합치기 위해 배열의 모든 원소를 순회하면서 하나의 집합 번호를 나머지 한 개의 집합 번호로 교체한다. 예를 들어 1 2 3 4 5 배열에서 3번 집합을 2번 집합으로 합치면 1 2 2 4 5가 된다. 다시 2번 집합을 1번 집합으로 합친다면 1 1 1 4 5가 된다.\n- Find연산 O(1): Array[i] 값이므로 한 번에 원소가 속하는 집합의 원소를 알 수 있다.\n\n배열로 Union-Find를 구현할 수는 있다. 하지만, Union연산의 시간복잡도는 O(N)으로 N이 커지면 백준 1717문제처럼 시간초과가 날 것이다. 그럼 트리구조를 사용한다면 **맞습니다!** 를 볼 수 있을까?\n\n### ✨트리로 표현하기\n\n- 한 집합에 속하는 원소들은 하나의 트리로 묶인다. 자료구조는 아래 그림과 같이 트리들의 집합으로 표현된다.\n\n![Union%20Find/Untitled.png](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2020-02-27-img/Untitled.png)\n\n- 트리의 루트 노드가 각 원소가 속한 집합의 번호가 된다.\n- Union 연산을 수행하기 전 두 원소가 같은 집합에 속하는 지 확인한다. 다른 집합에 속했을 때만 Union 연산을 수행한다. 즉, 두 원소의 루트 노드가 다르면 Union 연산을 수행한다.\n- Find 연산을 위해서는 모든 자식 노드가 부모에 대한 포인터 정보를 가지고 있어야 한다. 이렇게 해야 포인터를 따라 올라가 루트 노드를 찾을 수 있게 된다. 단, 부모 노드에서 자식 노드로 내려가는 일은 발생하지 않기 때문에 부모가 자식에 대한 포인터 정보를 가질 필요는 없다.\n\n**구현 방법**\n\n- 초기화: N개의 루트 노드를 생성하고 자기 자신을 가리키는 포인터를 갖도록 설정한다. 각각의 노드가 루트 노드가 된다.\n- Union연산: 각 트리의 루트를 찾은 뒤 루트 노드가 다르면 하나를 다른 한 쪽의 자손으로 넣어 두 트리를 합친다. 시간 복잡도는 루트 노드를 찾기 위해 Find연산을 수행하므로 Find연산 수행 시간이 지배한다.\n\n![Union%20Find/Untitled%201.png](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2020-02-27-img/Untitled%201.png)\n\n- Find연산: 각 노드에 저장된 포인터 정보를 따라 주어진 원소가 포함된 트리의 루트 노드를 찾는다. 트리의 높이와 시간 복잡도가 비례한다.\n\n## ✔백준 문제 풀이\n\n```cpp\n    #include <iostream>\n    #include <string>\n    using namespace std;\n\n    int s[1000001];\n    int n;\n\n    int find(int a) {\n    \tif (s[a] == a) return a;\n    \treturn s[a] = find(s[a]);\n    }\n\n    void fnc_union(int a, int b) {\n    \tif (a == b) return;\n    \ta =\tfind(a);\n    \tb = find(b);\n    \tif (a == b) return;\n    \ts[b] = a;\n    }\n\n\n    int main() {\n    \tint m;\n    \tscanf(\"%d %d\", &n, &m);\n\n    \tfor (int i=0; i<n+1; i++) {\n    \t\ts[i] = i;\n    \t}\n    \twhile (m--) {\n    \t\tint t, a, b;\n    \t\tscanf(\"%d %d %d\", &t, &a, &b);\n    \t\tif (t) {\n    \t\t\tif (find(a) == find(b)) printf(\"YES\\n\");\n    \t\t\telse printf(\"NO\\n\");\n    \t\t}\n    \t\telse fnc_union(a, b);\n    \t}\n    \treturn 0;\n    }\n```\n\n## 👏최적화하기\n\n트리 구조는 최악의 경우 완전히 비대칭적인 트리 즉, 연결리스트 형태가 된다. 예를 들어 두 트리 a, b를 합칠 때 항상 a의 루트 노드에 b의 루트 노드를 자손으로 합친다면 아래 그림과 같이 원소의 개수가 N개일 때, 트리의 높이가 N-1인 연결 리스트 형태가 된다. 최악의 경우 Union, Find 연산의 시간복잡도는 O(N)이 된다는 얘기다.\n\n![Union%20Find/Untitled%202.png](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2020-02-27-img/Untitled%202.png)\n\n해결 방법💊은 트리의 높이가 낮은 트리의 루트 노드에 합치는 것이다. 이렇게 하면 트리의 높이가 크게 높아지는 상황을 방지할 수 있다. 이러한 최적화를 Union-By-Rank 라고 하며 여기서 rank는 트리의 높이를 저장한다.\n\n**구현방법**\n\n- 두 트리를 합칠 때 랭크(높이)가 더 낮은 트리에 합친다.\n- 랭크에는 트리의 높이를 저장한다.\n- 두 트리의 랭크가 동일한 경우에 합쳐진 트리의 랭크를 1 증가시킨다.\n\n> 최적화 과정을 거치면 트리의 랭크는 합쳐진 두 트리의 랭크가 같을 때만 증가한다. 즉 높이 h인 트리는 높이 h-1인 트리 두개가 합쳐져야한다. 높이 h-1인 트리가 최소 x개의 노드를 가져야한다면 높이가 h가 되기 위해서는 2x개의 노드가 필요하다. 최적화를 통해 트리의 높이가 트리에 속한 **노드의 수의 로그에 비례**하는 것을 보장할 수 있게된다.\n\n백준 1717 최적화 코드\n\n```cpp\n    #include <iostream>\n    #include <string>\n    using namespace std;\n\n    int s[1000001];\n    int r[1000001] = {1};\n    int n;\n\n    int find(int a) {\n    \tif (s[a] == a) return a;\n    \treturn s[a] = find(s[a]); // 경로 압축 최적화\n    }\n\n    void fnc_union(int a, int b) {\n    \tif (a == b) return;\n    \ta =\tfind(a);\n    \tb = find(b);\n    \tif (a == b) return;\n    \t// 랭크 최적화 적용\n    \tif (r[a] > r[b]) swap(a, b);\n    \t\ts[a] = b;\n    \tif (r[a] == r[b]) r[b]++;\n    }\n\n\n    int main() {\n    \tint m;\n    \tscanf(\"%d %d\", &n, &m);\n\n    \tfor (int i=0; i<n+1; i++) {\n    \t\ts[i] = i;\n    \t}\n    \twhile (m--) {\n    \t\tint t, a, b;\n    \t\tscanf(\"%d %d %d\", &t, &a, &b);\n    \t\tif (t) {\n    \t\t\tif (find(a) == find(b)) printf(\"YES\\n\");\n    \t\t\telse printf(\"NO\\n\");\n    \t\t}\n    \t\telse fnc_union(a, b);\n    \t}\n    \treturn 0;\n    }\n```\n\n**경로 압축(Path Compression)**\n\n각 원소의 부모 노드를 재귀를 통해 찾아낸 루트 노드로 바꾸면 다음번 동일한 Find연산 수행 시 경로를 따라갈 필요없이 바로 루트를 찾을 수 있다. 재귀적인 구현으로 a에서 루트까지 올라가는 모든 경로 상에 있는 노드들에게 경로 압축 최적화가 자동으로 수행된다.\n\n```cpp\n    int find(int a) {\n    \tif (s[a] == a) return a;\n    \treturn s[a] = find(s[a]); // 경로 압축 최적화\n    }\n```\n\n![Union%20Find/Untitled%203.png](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2020-02-27-img/Untitled%203.png)\n\n위 최적화 과정을 모두 적용하면 연산 수행 시간을 분석하기 어려울 수 있다. 트리의 높이 변화에 따라 Find연산 수행 시간이 달라지기 때문이다. 평균 수행시간은 O(a(N))으로 a(N)은 에커만 함수를 이용해 정의되는 함수다. 거의 모든 크기의 N에 대해 4 이하의 값을 가져서 모든 입력에 대해 상수 시간에 동작한다고 봐도 무관하다.\n\n**관련 문제**\n\n[Disjoint-set](https://www.acmicpc.net/problem/tag/Disjoint-set)\n\n**참고 99.9%**\n\n[[자료구조]Union-Find: Disjoint Set의 표현](https://bowbowbow.tistory.com/26)\n"}}},"next":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"5a30bac6bb7fcaecb510c9cd70735f33591e0b4c","text":"# AWS 연습하자 2탄 - Jenkins와 Github 연동\n\n- Title : AWS 연습하자 2탄 - Jenkins와 Github 연동\n- Date : 2020-02-25\n- Category: Infra\n\n> AWS 연습하자 시리즈\n>\n> - [AWS 연습하자 1탄 - AWS EC2 인스턴스에 Jenkins 서버 구축하기](/post/2020-02-24-how-to-use-aws)\n\nAWS 연습하기 2탄에서는 추가 설정과 Jenkins와 Github을 연동하는 과정을 다뤄보겠습니다.\n\n# Git 설치\n\n연동에 앞서 Jenkins 서버에 git을 설치해두겠습니다.\n\n```\nsudo yum install git\n```\n\n# SSH 키 생성 및 등록\n\n젠킨스와 깃허브를 연동하는 작업은 [기억보다 기록을 - Jenkins로 Beanstalk + Multi Module 배포하기 - Jenkins와 Github 연동하기](https://jojoldu.tistory.com/291?category=777282)를 99% 참고하여 진행했습니다.\n\nssh 키를 생성합니다.\n\n```\nsudo ssh-keygen -t rsa -f id_rsa\n```\n\n아래 커맨드를 이용해 id_rsa 내용을 확인한 후 복사해둡니다.\n\n```\nsudo cat id_rsa\n```\n\n그 다음 다시 젠킨스 페이지로 돌아와서 **Credentials -> System -> Global credentials -> Add Credentials**를 선택합니다.\n\n아래와 같이 설정한 후 저장합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/19.PNG)\n\n이제 공개키(id_rsa.pub)를 Github에 등록하겠습니다.\nJenkins로 관리할 Github 프로젝트로 이동한 뒤 **Settings탭 -> Deploy keys -> Add deploy key** 를 차례로 클릭합니다.\n\nTitle에는 Jenkins 입력, key에는 아래 커맨드를 실행한 결과 값을 붙여넣습니다.\n\n```\nsudo cat id_rsa.pub\n```\n\nAllow write access는 체크 해제한 후 Add Key를 클릭합니다.\n\n이 작업만 해도 Build, Test, Code Clone 등을 다 할 수 있긴 합니다. PUSH 발생시에도 젠킨스가 PUSH 이벤트를 받을 수 있도록 Webhooks를 추가하겠습니다.\n\n**Settings 탭 -> Webhooks -> Add webhook** 을 클릭합니다.\n\nPayload URL에 http://Jenkins도메인/github-webhook/ 을 입력하고 Content type은 **application/json** 으로 변경해줍니다. Add webhook을 클릭하여 추가를 완료합니다.\n\n# Nodejs 설정\n\n제가 연결할 프로젝트는 express 프레임워크가 적용된 nodejs 서버입니다. 우선 Node.js 툴을 설치해줘야합니다. **메인페이지 -> Jenkins 관리 -> 플러그인 관리 -> 설치가능 탭** 을 클릭한 후 검색 창에 **nodejs** 라고 입력합니다. 리스트에서 NodeJS Plugin이 보이면 체크박스 선택 후 재시작없이 설치하기를 클릭합니다. 설치가 완료되면 다시 메인 페이지로 돌아갑니다.\n\n이제 Node.js 툴 설정을 진행하겠습니다. **Jenkins 관리 -> Global Tool Confituration** 을 선택합니다.\n\n**NodeJS 섹션 -> NodeJS installations..** 를 클릭합니다.\n\n아래와 같이 입력한 후 저장합니다.\n저는 로컬에서 노드 버전이 12.14.1 여서 다음과 같이 선택했습니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/16.PNG)\n\n# Item 생성 및 파이프라인 작성\n\n**새로운 Item -> 적당한 이름 입력 -> Pipeline** 선택 후 OK를 눌러줍니다.\n\nBuild Triggers가 Github hook과 연동되도록 다음과 같이 선택합니다.\n\n![process tree](https://raw.githubusercontent.com/devgaram/TIL/master/Infra/images/2020-02-24-img/20.PNG)\n\nPipeline 섹션에 Definition은 Pipeline script로 한 후 아래와 같이 입력하고 저장합니다. Pipeline 스크립트를 jenkinsfile로 관리하는 것은 뒤에서 다루도록 하겠습니다.\n\n```\npipeline {\n   agent any\n\n   tools {\n      nodejs \"node\"\n   }\n\n   stages {\n      stage('Build') {\n         steps {\n            git 'https://github.com/devgaram/express-project-blog.git'\n         }\n      }\n\n      stage('Install dependencies') {\n          steps {\n              sh 'npm install -g yarn'\n              sh 'yarn install'\n          }\n      }\n      stage('Test') {\n          steps {\n              echo 'test..'\n              // yarn test\n          }\n      }\n      stage('Upload S3') {\n          steps {\n              echo 'upload s3'\n          }\n      }\n      stage('Deploy') {\n          steps {\n              echo 'deploy'\n          }\n      }\n   }\n   post {\n        success {\n            echo 'successed'\n        }\n        failure {\n            echo 'failed'\n        }\n   }\n}\n\n```\n\n생성된 아이템으로 이동한 후 Build Now 버튼을 눌렀을 때 에러없이 완료되면 Github 연동은 성공적으로 된 것입니다.\n\n[AWS 연습하자 3탄 - Jenkins와 S3 버킷 & AWS codeDeploy 연동으로 배포하기](/post/2020-02-26-how-to-use-aws) 으로 이어집니다.\n\n[참고 블로그](https://medium.com/@gustavo.guss/jenkins-starting-with-pipeline-doing-a-node-js-test-72c6057b67d4)\n"}}}},"pageContext":{"id":"780e861698b99b29b1cd69f14ca08ded2b5349b5","previousPostId":"476dc1d82d78ebda7412a9be6dbf3ccf0973fbae","nextPostId":"5a30bac6bb7fcaecb510c9cd70735f33591e0b4c"}},"staticQueryHashes":["2685952063","2841359383"]}