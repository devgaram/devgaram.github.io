{"componentChunkName":"component---src-templates-blog-post-js","path":"/a1f625269928ae850f3014fdc0614633e4ee091c","result":{"data":{"site":{"siteMetadata":{"title":"보노보노의 평화로운 개발 이야기"}},"current":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"a1f625269928ae850f3014fdc0614633e4ee091c","text":"# 시스템 설계 및 규모 확장성 문제 1 - 중복 URL\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 1 - 중복 URL\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 중복 URL : 100억 개의 URL이 있다. 중복된 문서를 찾으려면 어떻게 해야 하는가? 여기서 '중복'이란 '같은 URL'이라는 뜻이다.\n\n## 내풀이\n\n만약 100억 개의 URL을 저장할 수 있는 충분한 공간이 있다면, 리스트를 정렬한 후 중복된 값 찾으면 될 것 같다.  \n아니면 100억 개의 URL을 해시테이블에 저장하는 전처리 과정을 하면 전처리 과정 중에도 중복된 문서를 찾을 수 있고\n그 후 데이터가 추가될 때도 쉽게 중복 여부를 확인할 수 있을 것 같다.\n\n## 책풀이\n\n## 1단계 : 합당한 가정을 세운다.\n\n책은 100억 개의 URL을 처리하기위한 공간을 계산하기위해 다음과 같은 합당한 가정을 세운다.\n\n- 각 URL이 평균적으로 100개의 문자로 구성되어 있고 각 문자는 4바이트라고 가정한다.\n- 100(문자) _ 4(bytes) _ 100억(url개수) = 4,000,000,000,000 bytes = 4 \\* 10<sup>12</sup> = 4TB\n- 즉, 100억 개의 URL을 처리하기위해서는 4TB 정도의 메모리 공간이 필요하다.\n\n## 2단계 : 현실적 제약을 무시한다.\n\n모든 데이터를 메모리에 보관할 수 있다고 가정한 후 문제에 접근한다.\n\n이미 살펴본 URL에 대해 true를 반환하는 해시테이블을 사용하여 문제를 해결할 수 있다.  \n리스트를 정렬하는 방식은 시간도 더 들고 장점도 없다.\n\n## 3단계 : 현실로 돌아온다.\n\n4TB의 데이터를 메모리(RAM)에 전부 올릴 수 없는 상황에서 어떻게 해야하는지 생각한다.\n\n**해법 #1 : 디스크 저장**\n\n각 URL을 .txt 파일에 저장한다.  \n.txt 파일의 크기는 1GB(10<sup>9</sup>)로 4TB URL을 저장하기위해서는 4000개의 파일이 필요하다.  \nx = hash(u) % 4000로 저장할 .txt 파일을 결정한다.  \n같은 해시값을 갖는 URL은 같은 파일에 저장된다.  \n각 파일을 메모리에 올려 URL의 해시테이블을 생성한 다음에 중복이 존재하는 지 확인하면 된다.\n\n**해법 #2 : 데이터를 여러 서버에 분할**\n\n본질적으로는 해법1과 같으나, 여러 서버를 사용한다는 차이가 있다.  \nURL을 .txt라는 파일에 저장하는 대신 서버 x에 전송하는 것이다.\n\n- 장점 : 병렬처리가능\n- 단점 : 4000개의 서버가 완벽 동작해야함(비현실적)\n"}}},"previous":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"d3dc616060fb13934c41fc45065d110b9e8704ee","text":"# 시스템 설계 및 규모 확장성 문제 5 - 판매순위\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 5 - 판매순위\n- Date : 2019-08-31\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 판매순위 : 한 전자상거래 회사는 가장 잘 팔리는 제품의 리스트(전체에서 그리고 각 목록별로)를 알고 싶어 한다. 예를 들어, 어떤 제품은 전체 제품 중에서 1,506번째로 잘 팔리지만 운동 장비 중에서는 13번째로 잘 팔리고, 안전용품 중에서는 24번째로 잘 팔릴 수 있다. 이 시스템을 어떻게 설계할지 설명하라.\n\n## 내풀이\n\n각 제품 정보에 판매수량을 저장을 하고 리스트 조회할 때마다 정렬하는 건 좀 그럴거 같긴한뎁,,\n동시에 전체 중 ~위 운동 장비 중 ~위.. 이런식으로 표현하게 되면 정렬을 넘 많이 하게 되는 듯싶은뎅\n구입할 때마다 리스트의 맨앞에..?음..\n매번 순위 조회할때마다 정렬해야되니깐 이건 좀 별루고\n아예 전체 연결리스트를 순서가 유지되게 하는 게 좋을 듯\n삽입 삭제가 빈번하니깐 연결리스트가 좋을거같고...\n\n## 책풀이\n\n**1단계 : 문제 범위를 한정하고 합리적인 가정을 하자**\n\n구현하려는 시스템을 다음과 같이 정의했다.\n\n- 잘 팔린다는 것은 판매량이 많다는 것을 의미한다.\n- 판매량은 평생/지난달/저번주 판매량인지 명확하게 정의할 것이다. 여기서는 저번주 판매량으로 한정한다.\n- 각 제품은 여러 목록에 포함될 수 있고 하위목록 개념은 없다고 가정한다.\n\n다음과 같은 합리적인 가정을 세웠다.\n\n- 통계 결과가 언제나 100% 최신 데이터가 아닐 수 있다고 가정할 것이다.\n- 인기 있는 제품의 경우 정확도가 중요하나 인기 없는 제품은 약간의 오차가 있어도 괜찮다.\n- 가장 인기 있는 제품의 경우 한 시간마다 갱신이 이루어진다고 가정할 것이다.\n\n**2단계 : 주요 구성요소 그리기**\n\n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/5-1.jpg) <br/>\n\n**3단계 : 핵심문제 파악**\n\n1. 분석은 비용이 비싸다.\n2. 데이터베이스에 너무 자주 기록한다.\n3. join 비용이 비싸다\n\n2번 데이터베이스에 너무 자주 기록된다.  \n구매할 때마다 판매량 정보 테이블을 업데이트하기보다는 모아서 일괄적(batch)으로 한번에 데이터베이스에 쓰는 방법을 쓴다.  \n즉, 곧바로 데이터베이스에 자료를 집어넣기보단, 메모리 내의 캐시와 같은 저장소에 구매 정보와 백업용 로그 파일을 저장해 놓은 뒤 주기적으로 로그/캐시 데이터를 모아서 한 번에 데이터베이스에 넣는 것이다. (특정 시점까지의 자료만 데이터베이스에 넣는 식)\n\n3번 join 비용이 비싸다.  \n수천 개의 제품 목록을 제품 ID에 join 하는 작업은 고비용이다.\n"}}},"next":{"repository":{"post":{"__typename":"GitHub_Blob","oid":"725f6823a549cb3bd4d8fddd15021a218c438de0","text":"# [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n\n- Title : [코딩인터뷰] 시스템 설계 및 규모 확장성 문제 2 - 소셜네트워크\n- Date : 2019-08-30\n- Category: Algorithm\n\n> 코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트\n\n# Q. 소셜 네트워크 : 페이스북이나 링크드인과 같은 대규모 소셜 네트워크를 위한 자료구조는 어떻게 설계하겠는가? 두 사람 사이의 최단 경로를 보여주는 알고리즘은 어떻게 설계하겠는가? (가령, 나->밥->수잔->제이슨->당신)\n\n## 내풀이\n\n'나'를 기준으로 '나'의 친구들을 연결할 필요가 있고, '친구'의 친구들을 연결할 필요가 있다.  \n각 사용자를 '노드'로 정의하고 관계를 '에지'로 정의한다고 하면 자료구조로 그래프를 사용하는 게 적절하다고 생각한다.  \n사용자 간의 경로 탐색은 너비우선탐색(BFS)로 하는 것이 적절하다고 생각한다.\n'나'를 기준으로 동심원을 그리며 찾는 것이 깊이우선탐색(DFS)보다 낫다.\nDFS는 '노드'를 기준으로 방문하지않은 노드 끝까지 갔다가 돌아가는 식으로 탐색하므로 최단경로가 아닐 수도 있다.\n\n## 책풀이\n\n## 단계1 : 문제를 단순화하기 - 수백만이 아닌 10명의 사용자로 생각해보기\n\n각 사용자를 노드, 친구 관계를 간선으로 설정하여 하나의 그래프를 만들 수 있다.  \n두 사용자 간의 경로는 한 사용자에서 시작해서 너비 우선 탐색을 돌려보면된다.\n혹은 양방향 너비 우선 탐색을 할 수도 있다.  \n하나는 출발지에서, 나머지 하나는 도착지에서 시작해서 너비 우선 탐색 두 개를 동시에 돌리는 것을 말한다.  \n두 탐색이 어느 지점에서 충돌하는 순간 경로를 찾은 것이다.\n\n**깊이우선탐색을 사용하지 않는 이유는?**  \n깊이 우선 탐색은 단순히 경로 하나를 찾기 때문이고, 이 경로가 가장 짧은 경로가 아닐 수도 있다.  \n또한, 경로 하나를 찾는 과정도 비효율적이다. 두 사용자가 1촌 관계라 하더라도 하위 트리에 존재하는 수백만 개의 노드를 탐색하게 될 수 있기 때문이다.\n\n**구현방법**  \n![1](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-1.jpg) <br/>\n![2](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-2.jpg) <br/>\n![3](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-3.jpg) <br/>\n![4](https://raw.githubusercontent.com/devgaram/TIL/master/Algorithm/images/2019-08-30-img/2-4.jpg) <br/>\n\n양방향 너비 우선 탐색이 일반 너비 우선 탐색보다 빠르다.  \nS와 D가 친구 C를 공유할 때, (각 사용자는 K명의 친구가 있다, q는 경로의 길이)\n\n- 일반적인 너비 우선 탐색으로 S -> D로 가려면 대략 K + K\\*K개의 노드를 거쳐야 한다. = Q(K<sup>q</sup>)\n- 양방향 너비 우선 탐색은 S 친구 K, D친구 K로 2K 노드만 거치면 된다. = Q(K<sup>q/2</sup>)\n\n단, 양방향 너비 우선 탐색은 시작 지점과 도착 지점 모두 접근 가능할 때에나 사용 가능하다.\n\n## 단계2 : 수백만 사용자의 처리\n\n링크드인이나 페이스북 규모의 서비스를 만들 때에는 컴퓨터 하나만으로는 부족하다.  \n다시 말해 Person을 위와 같이 단순하게 설계해서는 제대로 동작하지 않을 것이라는 뜻이다.  \n우리가 찾는 '친구'는 같은 서버에 있지 않을 수도 있다.  \n따라서 ID로 구성되는 친구 리스트를 만들고, ID를 통해 해당 사용자 정보가 있는 컴퓨터 정보를 얻는다.  \n얻은 컴퓨터 정보 안에서 사용자 정보를 다시 탐색한다.  \n효율적 탐색을 위해서 해시테이블을 사용한다.\n\n**최적화하기**\n\n- 다른 서버에 대한 탐색을 줄인다.\n- 컴퓨터에 사용자 정보를 분배할 때, 무작위로 나누는 것이 아닌 사용자가 거주하는 나라나 시, 도, 군 등의 정보를 이용한다.\n"}}}},"pageContext":{"id":"a1f625269928ae850f3014fdc0614633e4ee091c","previousPostId":"d3dc616060fb13934c41fc45065d110b9e8704ee","nextPostId":"725f6823a549cb3bd4d8fddd15021a218c438de0"}},"staticQueryHashes":["2685952063","2841359383"]}